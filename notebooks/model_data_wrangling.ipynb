{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame keys: dict_keys(['satcat', 'psatcat', 'celestrak'])\n",
      "Cleaned DataFrame keys: dict_keys(['satcat', 'psatcat', 'celestrak'])\n",
      "(59784, 53)\n",
      "Index(['JCAT_number', 'Sat_catalog', 'object_id', 'object_type', 'object_name',\n",
      "       'payload_name', 'launch_date', 'orbit_date', 'oper_time', 'oper_orbit',\n",
      "       'parent_object', 'program', 'object_state', 'object_owner',\n",
      "       'owner_state', 'manufacturer', 'launch_site', 'control', 'destination',\n",
      "       'class', 'category', 'discipline', 'comment', 'status', 'status_date',\n",
      "       'data_status', 'phase_end_date', 'end_transmit_date', 'last_time',\n",
      "       'time_flag', 'decay_date', 'result', 'bus', 'motor', 'mass', 'dry_mass',\n",
      "       'total_mass', 'length', 'diameter', 'span', 'shape', 'rcs_value',\n",
      "       'orbit_center', 'orbit_type', 'perigee_km', 'apogee_km', 'inclination',\n",
      "       'inc_category', 'period_mins', 'plane', 'maneuver', 'alternate_names',\n",
      "       'UN_reg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "# Define the path to the data files\n",
    "datapath = '../data/'\n",
    "# List of filenames to be processed\n",
    "filenames = ['satcat.csv', 'psatcat.csv', 'celestrak_satcat.csv']\n",
    "\n",
    "# Column renaming maps for each dataset\n",
    "col_dicts = [\n",
    "    # Column mapping for SATCAT dataset\n",
    "    {\n",
    "        '#JCAT': 'JCAT_number', 'Satcat': 'Sat_catalog', 'Piece': 'object_id',\n",
    "        'Type': 'sat_type', 'Name': 'object_name', 'PLName': 'payload_name',\n",
    "        'LDate': 'launch_date', 'Parent': 'parent_object', 'SDate': 'status_date',\n",
    "        'Primary': 'primary', 'DDate': 'phase_end_date', 'Status': 'status',\n",
    "        'Dest': 'destination', 'Owner': 'object_owner', 'State': 'object_state',\n",
    "        'Manufacturer': 'manufacturer', 'Bus': 'bus', 'Motor': 'motor', 'Mass': 'mass',\n",
    "        'MassFlag': 'mass_flag', 'DryMass': 'dry_mass', 'DryFlag': 'dry_flag',\n",
    "        'TotMass': 'total_mass', 'TotFlag': 'total_flag', 'Length': 'length',\n",
    "        'LFlag': 'length_flag', 'Diameter': 'diameter', 'DFlag': 'diameter_flag',\n",
    "        'Span': 'span', 'SpanFlag': 'span_flag', 'Shape': 'shape', 'ODate': 'orbit_date',\n",
    "        'Perigee': 'perigee_km', 'PF': 'perigee_flag', 'Apogee': 'apogee_km',\n",
    "        'AF': 'apogee_flag', 'Inc': 'inclination', 'IF': 'incl_flag', 'OpOrbit': 'oper_orbit',\n",
    "        'OQUAL': 'orbit_quality', 'AltNames': 'alternate_names'\n",
    "    },\n",
    "    # Column mapping for PSATCAT dataset\n",
    "    {\n",
    "        '#JCAT': 'JCAT_number', 'Piece': 'object_id', 'Name': 'object_name',\n",
    "        'LDate': 'launch_date', 'TLast': 'last_time', 'TOp': 'oper_time',\n",
    "        'TDate': 'end_transmit_date', 'TF': 'time_flag', 'Program': 'program',\n",
    "        'Plane': 'plane', 'Att': 'attitude', 'Mvr': 'maneuver', 'Class': 'class',\n",
    "        'Category': 'category', 'UNState': 'owner_state', 'UNReg': 'UN_reg',\n",
    "        'UNPeriod': 'period_mins', 'UNPerigee': 'perigee_km', 'UNApogee': 'apogee_km',\n",
    "        'UNInc': 'inclination', 'Result': 'result', 'Control': 'control',\n",
    "        'Discipline': 'discipline', 'Comment': 'comment'\n",
    "    },\n",
    "    # Column mapping for Celestrak dataset\n",
    "    {\n",
    "        'OBJECT_NAME': 'object_name', 'OBJECT_ID': 'object_id', 'NORAD_CAT_ID': 'norad_cat_id',\n",
    "        'OBJECT_TYPE': 'object_type', 'OPS_STATUS_CODE': 'ops_status_code', 'OWNER': 'owner_state',\n",
    "        'LAUNCH_DATE': 'launch_date', 'LAUNCH_SITE': 'launch_site', 'DECAY_DATE': 'decay_date',\n",
    "        'PERIOD': 'period_mins', 'INCLINATION': 'inclination', 'APOGEE': 'apogee_km',\n",
    "        'PERIGEE': 'perigee_km', 'RCS': 'rcs_value', 'DATA_STATUS_CODE': 'data_status',\n",
    "        'ORBIT_CENTER': 'orbit_center', 'ORBIT_TYPE': 'orbit_type'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Harvard designation order for piece IDs\n",
    "PIECE_ID_HARVARD_DESIGNATION_ORDER = {\n",
    "    1: 'ALP', 2: 'BET', 3: 'GAM', 4: 'DEL', 5: 'EPS', 6: 'ZET', 7: 'ETA', 8: 'THE', 9: 'IOT', 10: 'KAP',\n",
    "    11: 'LAM', 12: 'MU', 13: 'NU', 14: 'XI', 15: 'OMI', 16: 'PI', 17: 'RHO', 18: 'SIG', 19: 'TAU', 20: 'UPS',\n",
    "    21: 'PHI', 22: 'CHI', 23: 'PSI', 24: 'OME', 25: 'A ALP', 26: 'A BET', 27: 'A GAM', 28: 'A DEL', 29: 'A EPS', 30: 'A ZET',\n",
    "    31: 'A ETA', 32: 'A THE', 33: 'A IOT', 34: 'A KAP', 35: 'A LAM', 36: 'A MU', 37: 'A NU', 38: 'A XI', 39: 'A OMI', 40: 'A PI',\n",
    "    41: 'A RHO', 42: 'A SIG', 43: 'A TAU', 44: 'A UPS', 45: 'A PHI', 46: 'A CHI', 47: 'A PSI', 48: 'A OME', 49: 'B ALP', 50: 'B BET',\n",
    "    51: 'B GAM', 52: 'B DEL', 53: 'B EPS', 54: 'B ZET', 55: 'B ETA', 56: 'B THE', 57: 'B IOT', 58: 'B KAP', 59: 'B LAM', 60: 'B MU',\n",
    "    61: 'B NU', 62: 'B XI', 63: 'B OMI', 64: 'B PI', 65: 'B RHO', 66: 'B SIG', 67: 'B TAU', 68: 'B UPS', 69: 'B PHI', 70: 'B CHI',\n",
    "    71: 'B PSI', 72: 'B OME'\n",
    "}\n",
    "\n",
    "# Load a DataFrame from a CSV file\n",
    "def load_dataframe(datapath, filename):\n",
    "    return pd.read_csv(f'{datapath}{filename}', low_memory=False)\n",
    "\n",
    "# Apply cleaning steps to a DataFrame\n",
    "def apply_cleaning_steps(df, col_rename_map):\n",
    "    df = col_renaming_mapper(df, col_rename_map)\n",
    "    df = date_formatter(df, df.columns)\n",
    "    df = fix_mixed_data_types(df)\n",
    "    df = null_handler(df)\n",
    "    df = df.replace({'?': 'Unknown', 'UNK': 'Unknown', 'Unk': 'Unknown'})  # Ensure 'UNK' is replaced with 'Unknown'\n",
    "    return df\n",
    "\n",
    "# Format specified columns in a DataFrame to datetime format\n",
    "def date_formatter(dataframe, columns):\n",
    "    for c in columns:\n",
    "        if 'datetime' not in str(type(dataframe.dtypes[c])).lower():\n",
    "            if ('_jd' in c.lower()) or ('julian_date' in c.lower()):\n",
    "                dataframe[c] = pd.to_datetime(dataframe[c], unit='D', origin='julian')\n",
    "            elif ((('date' in c.lower()) or ('time' in c.lower())) and 'flag' not in c.lower()):\n",
    "                dataframe[c] = pd.to_datetime(dataframe[c], errors='coerce', format='mixed')\n",
    "    return dataframe\n",
    "\n",
    "# Rename columns of a DataFrame based on a list of dictionaries\n",
    "def col_renaming_mapper(df, col_name_dict_list):\n",
    "    for d in col_name_dict_list:\n",
    "        if all(col in df.columns for col in d.keys()):\n",
    "            df = df.rename(columns=d)\n",
    "            return df\n",
    "    return df\n",
    "\n",
    "# Fix mixed data types and clean strings in a DataFrame\n",
    "def fix_mixed_data_types(df):\n",
    "    def try_convert(value):\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return value\n",
    "\n",
    "    def clean_string(value):\n",
    "        if isinstance(value, str):\n",
    "            value = re.sub(r'\\s+', ' ', value.strip())  # Replace multiple spaces with a single space and strip leading/trailing spaces\n",
    "        return value\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: clean_string(str(x)) if isinstance(x, str) else x)\n",
    "        df[col] = df[col].apply(lambda x: try_convert(x) if isinstance(x, str) else x)\n",
    "\n",
    "    mixed_types = check_mixed_types(df)\n",
    "    for col, types in mixed_types.items():\n",
    "        if len(types) <= 3 and str in types and float in types:\n",
    "            df[col] = df[col].apply(lambda x: try_convert(x) if isinstance(x, str) else x)\n",
    "            if len(df[col].map(type).unique()) > 1:\n",
    "                df[col] = df[col].apply(lambda x: str(x) if isinstance(x, float) else x)\n",
    "    return df\n",
    "\n",
    "# Identify columns with mixed data types in a DataFrame\n",
    "def check_mixed_types(df):\n",
    "    mixed_types_columns = {}\n",
    "    timestamp_type = pd._libs.tslibs.timestamps.Timestamp\n",
    "    nat_type = pd._libs.tslibs.nattype.NaTType\n",
    "    for col in df.columns:\n",
    "        types = df[col].map(type).unique().tolist()\n",
    "        if len(types) > 1 and not (len(types) == 2 and timestamp_type in types and nat_type in types):\n",
    "            mixed_types_columns[col] = types\n",
    "    return mixed_types_columns\n",
    "\n",
    "# Handle null values and duplicates in a DataFrame\n",
    "def null_handler(df):\n",
    "    df = df.replace(['-', 'nan'], [None, None])\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.dropna(thresh=df.shape[1]-(df.shape[1] - 2), axis=0)\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# Convert piece number to corresponding letter(s) in base 24 system (omitting I and O)\n",
    "def piece_number_to_letter(piece_number):\n",
    "    letters = \"ABCDEFGHJKLMNPQRSTUVWXYZ\"\n",
    "    result = \"\"\n",
    "    while piece_number > 0:\n",
    "        piece_number -= 1\n",
    "        result = letters[piece_number % 24] + result\n",
    "        piece_number //= 24\n",
    "    return result\n",
    "\n",
    "# Get the number corresponding to a Harvard designation\n",
    "def get_harvard_designation_number(harvard_designation):\n",
    "    return {v: k for k, v in PIECE_ID_HARVARD_DESIGNATION_ORDER.items()}.get(harvard_designation)\n",
    "\n",
    "# Convert piece ID in Harvard designation format to launch order format\n",
    "def convert_to_launch_order_format(object_id):\n",
    "    if re.match(r'^\\d{4}-\\d{3}[A-Z]+$', object_id):\n",
    "        return object_id\n",
    "    parts = object_id.split()\n",
    "    year = parts[0]\n",
    "    harvard_designation = None\n",
    "    piece_number = 1\n",
    "\n",
    "    if len(parts) == 2:\n",
    "        harvard_designation = parts[1]\n",
    "    elif len(parts) == 3:\n",
    "        harvard_designation = parts[1] if parts[2].isdigit() else f\"{parts[1]} {parts[2]}\"\n",
    "        piece_number = int(parts[2]) if parts[2].isdigit() else 1\n",
    "    elif len(parts) == 4:\n",
    "        harvard_designation = f\"{parts[1]} {parts[2]}\"\n",
    "        piece_number = int(parts[3])\n",
    "\n",
    "    harvard_number = get_harvard_designation_number(harvard_designation)\n",
    "    piece_letter = piece_number_to_letter(piece_number)\n",
    "    \n",
    "    if harvard_number is not None and piece_letter is not None:\n",
    "        return f\"{year}-{harvard_number:03d}{piece_letter}\"\n",
    "    return object_id\n",
    "\n",
    "# Fill missing 'object_type' values based on 'sat_type' values\n",
    "def fill_object_type(row):\n",
    "    if pd.isna(row['object_type']) and pd.notna(row['sat_type']):\n",
    "        if row['sat_type'].startswith('P'):\n",
    "            return 'PAY'\n",
    "        elif row['sat_type'].startswith('D') or row['sat_type'].startswith('C'):\n",
    "            return 'DEB'\n",
    "        elif row['sat_type'].startswith('R'):\n",
    "            return 'R/B'\n",
    "    return row['object_type']\n",
    "\n",
    "# Clean specific columns in a DataFrame by removing square brackets and trailing question marks\n",
    "def clean_dataframe(df, columns_to_clean):\n",
    "    def remove_square_brackets(value):\n",
    "        return value.replace('[', '').replace(']', '') if isinstance(value, str) else value\n",
    "\n",
    "    def remove_trailing_question_mark(value):\n",
    "        return value[:-1] if isinstance(value, str) and value.endswith('?') else value\n",
    "\n",
    "    for col in columns_to_clean:\n",
    "        df[col] = df[col].apply(remove_square_brackets)\n",
    "\n",
    "    df = df.map(remove_trailing_question_mark)\n",
    "    return df\n",
    "\n",
    "# Filter out columns with uniform values or nearly uniform values\n",
    "def filter_columns(df):\n",
    "    drop_columns = [col for col in df.columns if len(df[col].value_counts()) == 1 or (len(df[col].value_counts()) == 2 and 1 in df[col].value_counts().values)]\n",
    "    return df.drop(columns=drop_columns)\n",
    "\n",
    "# Load data into a dictionary of DataFrames\n",
    "df_dict = {filename.split('.')[0].split('_')[0]: load_dataframe(datapath, filename) for filename in filenames}\n",
    "\n",
    "# Print the keys of the df_dict to check for correct naming\n",
    "print(\"DataFrame keys:\", df_dict.keys())\n",
    "\n",
    "# Apply data cleaning steps to each DataFrame in the dictionary\n",
    "for key in df_dict:\n",
    "    df_dict[key] = apply_cleaning_steps(df_dict[key], col_dicts)\n",
    "\n",
    "# Print the keys of the cleaned DataFrames to ensure they exist\n",
    "print(\"Cleaned DataFrame keys:\", df_dict.keys())\n",
    "\n",
    "# Assign cleaned DataFrames to variables\n",
    "satcat_df, psatcat_df, celestrak_df = df_dict['satcat'], df_dict['psatcat'], df_dict['celestrak']\n",
    "\n",
    "# Convert 'object_id' column in SATCAT and PSATCAT DataFrames to launch order format\n",
    "satcat_df['object_id'] = satcat_df['object_id'].apply(convert_to_launch_order_format)\n",
    "psatcat_df['object_id'] = psatcat_df['object_id'].apply(convert_to_launch_order_format)\n",
    "\n",
    "# Set 'object_id' as the index for merging\n",
    "for df in df_dict.values():\n",
    "    df.set_index('object_id', inplace=True)\n",
    "\n",
    "# Combine DataFrames with preference order: SATCAT, PSATCAT, CELESTRAK\n",
    "combined_df = satcat_df.combine_first(psatcat_df).combine_first(celestrak_df)\n",
    "\n",
    "# Update 'object_name' column in combined DataFrame with preferred column from CELESTRAK DataFrame\n",
    "combined_df['object_name'] = celestrak_df['object_name'].combine_first(combined_df['object_name'])\n",
    "\n",
    "# Reset the index to bring 'object_id' back as a column\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "# Split 'oper_orbit' column into 'oper_orbit' and 'inc_category'\n",
    "split_oper_orbit = combined_df['oper_orbit'].str.split('/', expand=True)\n",
    "combined_df['oper_orbit'], combined_df['inc_category'] = split_oper_orbit[0], split_oper_orbit[1]\n",
    "\n",
    "# Fill NaN values in 'object_type' column based on 'sat_type' column\n",
    "combined_df['object_type'] = combined_df.apply(fill_object_type, axis=1)\n",
    "\n",
    "# Clean specific columns in the combined DataFrame\n",
    "combined_df = clean_dataframe(combined_df, ['object_state', 'owner_state'])\n",
    "\n",
    "# Reorder columns in the combined DataFrame\n",
    "columns_list = [\n",
    "    'JCAT_number', 'Sat_catalog', 'object_id', 'object_type', 'object_name', \n",
    "    'payload_name', 'launch_date', 'orbit_date', 'oper_time', 'oper_orbit', \n",
    "    'parent_object', 'program', 'object_state', 'object_owner', \n",
    "    'owner_state', 'manufacturer', 'launch_site', 'control', 'destination', \n",
    "    'class', 'category', 'discipline', 'comment', 'status', 'status_date', \n",
    "    'data_status', 'phase_end_date', 'end_transmit_date', 'last_time', \n",
    "    'time_flag', 'decay_date', 'result', 'bus', 'motor', 'mass', 'dry_mass', \n",
    "    'total_mass', 'length', 'diameter', 'span', 'shape', 'rcs_value', \n",
    "    'orbit_center', 'orbit_type', 'perigee_km', 'apogee_km', 'inclination', \n",
    "    'inc_category', 'period_mins', 'plane', 'maneuver', 'alternate_names', \n",
    "    'UN_reg'\n",
    "]\n",
    "combined_df = combined_df.reindex(columns=columns_list)\n",
    "\n",
    "# Replace '?' and 'UNK' with 'Unknown' in the entire DataFrame\n",
    "combined_df.replace({'?': 'Unknown', 'UNK': 'Unknown', 'Unk': 'Unknown'}, inplace=True)\n",
    "\n",
    "# Filter out columns with uniform values or nearly uniform values\n",
    "combined_df = filter_columns(combined_df)\n",
    "\n",
    "# Drop rows where the 'status' column is null\n",
    "combined_df.dropna(subset=['status'], inplace=True)\n",
    "\n",
    "# Define the mapping for converting status values\n",
    "status_conversion = {'AR': 'R', 'AO': 'O', 'ATT': 'DK', 'TFR': 'DK', 'GRP': 'DK', 'OX': 'ERR', 'C': 'E'}\n",
    "\n",
    "# Convert status values in the 'status' column\n",
    "combined_df['status'] = combined_df['status'].replace(status_conversion)\n",
    "\n",
    "# Define the list of statuses to drop\n",
    "statuses_to_drop = ['DSO', 'DSA', 'REL', 'EVA DP']\n",
    "\n",
    "# Drop rows where the 'status' column has values to be removed\n",
    "combined_df = combined_df[~combined_df['status'].isin(statuses_to_drop)]\n",
    "\n",
    "# Save the cleaned and combined DataFrame to a CSV file\n",
    "combined_df.to_csv('../data/combined_df.csv', index=False)\n",
    "\n",
    "# Save the cleaned and combined DataFrame to a .joblib file\n",
    "joblib.dump(combined_df, '../artifacts/combined_df.joblib')\n",
    "\n",
    "# Print the shape and columns of the combined DataFrame\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
